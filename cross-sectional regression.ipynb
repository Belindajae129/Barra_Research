{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataHub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numpy and pandas \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import calendar\n",
    "\n",
    "# If the observations are in a dataframe, you can use statsmodels.formulas.api to do the regression instead\n",
    "from statsmodels import regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_list=['BetaExp', 'DividendYieldExp',\n",
    "       'EarningsQualityExp', 'EarningsYieldExp', 'GrowthExp', 'LeverageExp',\n",
    "       'LiquidityExp', 'LongTermReversalExp', 'ManagementQualityExp',\n",
    "       'MidCapitalizationExp', 'MomentumExp', 'ProfitabilityExp',\n",
    "       'ProspectExp', 'SizeExp', 'ValueExp', 'ResidualVolatilityExp',\n",
    "       'AirlinesExp', 'AluminumSteelExp', 'ApparelandTextilesExp',\n",
    "       'AutomobilesandComponentsExp', 'BanksExp', 'BeveragesTobaccoExp',\n",
    "       'BiotechnologyLifeSciencesExp', 'BuildingProductsExp', 'ChemicalsExp',\n",
    "       'CommercialandProfessionalServicesExp', 'CommunicationsEquipmentExp',\n",
    "       'ComputersElectronicsExp', 'ConstructionMaterialsExp',\n",
    "       'ConstructionandEngineeringExp', 'ConstructionandFarmMachineryExp',\n",
    "       'ContainersandPackagingExp', 'DistributorsMultilineRetailExp',\n",
    "       'DiversifiedFinancialsExp', 'DiversifiedTelecommunicationServicesExp',\n",
    "       'ElectricUtilitiesExp', 'ElectricalEquipmentExp', 'FoodProductsExp',\n",
    "       'FoodandStaplesRetailingExp', 'GasUtilitiesExp',\n",
    "       'HealthCareEquipmentandTechnologyExp', 'HealthCareProvidersExp',\n",
    "       'HomebuildingExp', 'HotelsLeisureandConsumerServicesExp',\n",
    "       'HouseholdDurablesExp', 'HouseholdandPersonalProductsExp',\n",
    "       'IndustrialConglomeratesExp', 'IndustrialMachineryExp',\n",
    "       'InsuranceBrokersandReinsuranceExp', 'InternetSoftwareandITServicesExp',\n",
    "       'InternetandCatalogRetailExp',\n",
    "       'LeisureProductsTextilesApparelandLuxuryExp',\n",
    "       'LifeHealthandMultilineInsuranceExp', 'ManagedHealthCareExp',\n",
    "       'MediaExp', 'MultiUtilitiesWaterUtilitiesPowerExp',\n",
    "       'OilGasandConsumableFuelsExp', 'OilandGasDrillingExp',\n",
    "       'OilandGasEquipmentandServicesExp',\n",
    "       'OilandGasExplorationandProductionExp', 'PaperandForestProductsExp',\n",
    "       'PharmaceuticalsExp', 'PreciousMetalsGoldMiningExp', 'RealEstateExp',\n",
    "       'RestaurantsExp', 'RoadandRailExp', 'SemiconductorEquipmentExp',\n",
    "       'SemiconductorsExp', 'SoftwareExp', 'SpecialtyChemicalsExp',\n",
    "       'SpecialtyRetailExp', 'SpecialtyStoresExp',\n",
    "       'TradingCompaniesandDistributorsExp',\n",
    "       'TransportationAirFreightandMarineExp',\n",
    "       'WirelessTelecommunicationServicesExp']\n",
    "style_factor=['BetaExp', 'DividendYieldExp',\n",
    "       'EarningsQualityExp', 'EarningsYieldExp', 'GrowthExp', 'LeverageExp',\n",
    "       'LiquidityExp', 'LongTermReversalExp', 'ManagementQualityExp',\n",
    "       'MidCapitalizationExp', 'MomentumExp', 'ProfitabilityExp',\n",
    "       'ProspectExp', 'SizeExp', 'ValueExp', 'ResidualVolatilityExp']\n",
    "N18='return_shift'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/software/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/software/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-237-ab4ee6c8a19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0meigenvalue_lack_factor_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvalue12_1_lack_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myymm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0meigenvalue_lack_factor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvalue_lack_factor_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "# use eigenvalue1 to store the first eigen of residuals in each month        \n",
    "eigenvalue1=[]\n",
    "# use eigenvalue2 to store the first eigen of raw return in each month\n",
    "eigenvalue2=[]\n",
    "# use yymm to store the year and month for drawing data\n",
    "yymm=[]\n",
    "\n",
    "# \n",
    "eigenvalue_lack_factor=pd.DataFrame()\n",
    "\n",
    "for year in range(2018,2019):\n",
    "    for month in range(3,4):\n",
    "        yymm.append(year*100+month)\n",
    "        mrange=calendar.monthrange(year,month)\n",
    "        start_date= '%d%02d%02d'%(year,month,1)\n",
    "        end_date = '%d%02d%02d'%(year,month,mrange[1])\n",
    "        # load monthly data\n",
    "        loadings = h.read('DailyFactor', start=start_date, end=end_date)\n",
    "        # count(distinct(date)) to get the number of available dates, N\n",
    "        Ndays=loadings['date'].unique().shape[0]\n",
    "        # count(*) group by TICKER_US to get a table with number of records (dates) for each ticker\n",
    "        loadings_ndays=loadings[['date', 'ticker']].groupby('ticker').count().reset_index()\n",
    "        tickers=loadings_ndays[loadings_ndays['date']==Ndays]['ticker']\n",
    "        # Filter the table above by selecting the ticker with number of records (days) equal to N\n",
    "        loadings=loadings.loc[loadings['ticker'].isin(list(tickers))]\n",
    "        # Note that the Return data stored in risklab has left out the percentage\n",
    "        loadings['ReturnPct']=loadings['ReturnPct']*0.01\n",
    "        \n",
    "        # shifting tomorrow's return to today's row\n",
    "        loadings['return_shift'] = loadings.groupby('ticker')['ReturnPct'].shift(-1)\n",
    "        loadings=loadings.dropna()\n",
    "        # set multiindex       \n",
    "        loadings=loadings.set_index(['date', 'ticker']).sort_index()\n",
    "        # draw out the timestamp for every month\n",
    "        M=loadings.index.get_level_values(0)\n",
    "        Timestamp = []\n",
    "        for i in M:\n",
    "            if not i in Timestamp:\n",
    "                Timestamp.append(i)\n",
    "\n",
    "\n",
    "\n",
    "        residual = pd.DataFrame()\n",
    "        for i in range(len(Timestamp)):\n",
    "            Xi = pd.DataFrame()\n",
    "            # For each month, we load 'retun_shift' \n",
    "            Yi = np.array((loadings.loc[(Timestamp[i],slice(None)),'return_shift']).reset_index(drop=True))\n",
    "\n",
    "            for j in range(len(name_list)):\n",
    "                # For each month, we load all the exposures and store them as a dataframe. The columns of the dataframe are the regressors we will use.\n",
    "                Xij = np.array((loadings.loc[(Timestamp[i],slice(None)),name_list[j]]).reset_index(drop=True))\n",
    "                Xi[j] = Xij\n",
    "            # linear regression\n",
    "            linreg.fit(Xi, Yi)\n",
    "            residuali = np.array(Yi - linreg.predict(Xi))\n",
    "            residual[i]=residuali\n",
    "        residualT=residual.T\n",
    "        residualT=residualT.fillna(method='ffill')\n",
    "        residual=residualT.T\n",
    "        P= np.dot(residualT.values,residual.values)\n",
    "        P=P/(residualT.shape[1])\n",
    "        eigenvalue12_1,featurevector=np.linalg.eig(P)\n",
    "        eigenvalue12_1=sorted(list(eigenvalue12_1),reverse=True)\n",
    "        eigenvalue1.append(np.max(eigenvalue12_1))\n",
    "\n",
    "        # Construct a dataframe only for return\n",
    "        Ri=pd.DataFrame()\n",
    "        for i in range(len(Timestamp)):\n",
    "            Rij = np.array((loadings.loc[(Timestamp[i],slice(None)),N18]).reset_index(drop=True))\n",
    "            Ri[i]=Rij\n",
    "        Return_shift=Ri.T\n",
    "        Return_shift=Return_shift.fillna(method='ffill')\n",
    "        Return_shiftT=Return_shift.T\n",
    "        Q= np.dot(Return_shift.values,Return_shiftT.values)\n",
    "        Q = Q/(Ri.shape[0])\n",
    "        eigenvalue12_2,featurevector2=np.linalg.eig(Q)\n",
    "        eigenvalue12_2=sorted(list(eigenvalue12_2),reverse=True)\n",
    "        eigenvalue2.append(np.max(eigenvalue12_2))\n",
    "       \n",
    "    \n",
    "        eigenvalue_lack_factor_array=[]\n",
    "        for k in range(16):\n",
    "            # Remove one style factor at a time\n",
    "            name_list_lack_factor=name_list[:k]+name_list[k+1:]\n",
    "            residual = pd.DataFrame()\n",
    "            for i in range(len(Timestamp)):\n",
    "                Xi = pd.DataFrame()\n",
    "                Yi = np.array((loadings.loc[(Timestamp[i],slice(None)),N18]).reset_index(drop=True))\n",
    "\n",
    "                for j in range(len(name_list_lack_factor)):\n",
    "                    Xij = np.array((loadings.loc[(Timestamp[i],slice(None)),name_list_lack_factor[j]]).reset_index(drop=True))\n",
    "                    Xi[j] = Xij\n",
    "                linreg.fit(Xi, Yi)\n",
    "                residuali = Yi - linreg.predict(Xi)\n",
    "                residual[i]=residuali\n",
    "            residualT=residual.T\n",
    "            residualT=residualT.fillna(method='ffill')\n",
    "            residual=residualT.T\n",
    "            P= np.dot(residualT.values,residual.values)\n",
    "            P=P/(residualT.shape[1])\n",
    "            eigenvalue12_1_lack_factor,featurevector=np.linalg.eig(P)\n",
    "            eigenvalue12_1_lack_factor=sorted(list(eigenvalue12_1_lack_factor),reverse=True)\n",
    "            eigenvalue_lack_factor_array.append(np.max(eigenvalue12_1_lack_factor))\n",
    "        \n",
    "        for m in len(yymm):\n",
    "            eigenvalue_lack_factor[m]=np.array(eigenvalue_lack_factor_array)\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0005326890526634271, 0.0006236050052613793]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalue1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.003255472085076872, 0.00216137135929158]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalue2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.000627  0.000624  0.000624  0.000624  0.000624  0.000624  0.000626   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.000624  0.000624  0.000626  0.000627  0.000624  0.000624  0.000624   \n",
       "\n",
       "         14        15  \n",
       "0  0.000623  0.000628  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalue_lack_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_eigens=eigenvalue1\n",
    "residual_eigens_mom=eigenvalue1_mom\n",
    "residual_eigens_str=eigenvalue1_str\n",
    "residual_eigens_size=eigenvalue1_size\n",
    "residual_eigens_value=eigenvalue1_value\n",
    "residual_eigens_vol=eigenvalue1_vol\n",
    "residual_eigens_beta=eigenvalue1_beta\n",
    "return_eigens=eigenvalue2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "date = pd.period_range(\"2006-01\", freq=\"M\", periods=156)\n",
    "df1 = pd.DataFrame({\"date\":date, \"first_eigens\" : np.array(return_eigens)})\n",
    "df2 = pd.DataFrame({\"date\":date, \"first_eigens\" : np.array(residual_eigens)})\n",
    "df2_mom = pd.DataFrame({\"date\":date, \"first_eigens\" : np.array(residual_eigens_mom)})\n",
    "df2_str = pd.DataFrame({\"date\":date, \"first_eigens\" : np.array(residual_eigens_str)})\n",
    "df2_size = pd.DataFrame({\"date\":date, \"first_eigens\" : np.array(residual_eigens_size)})\n",
    "df2_value = pd.DataFrame({\"date\":date, \"first_eigens\" : np.array(residual_eigens_value)})\n",
    "df2_vol = pd.DataFrame({\"date\":date, \"first_eigens\" : np.array(residual_eigens_vol)})\n",
    "df2_beta = pd.DataFrame({\"date\":date, \"first_eigens\" : np.array(residual_eigens_beta)})\n",
    "\n",
    "df1['eigen_class'] = 'return_eigens'\n",
    "df2_mom['eigen_class'] = 'residual_eigens_lack_mom'\n",
    "df2_str['eigen_class'] = 'residual_eigens_lack_str'\n",
    "df2_size['eigen_class'] = 'residual_eigens_lack_size'\n",
    "df2_value['eigen_class'] = 'residual_eigens_lack_value'\n",
    "df2_vol['eigen_class'] = 'residual_eigens_lack_vol'\n",
    "df2_beta['eigen_class'] = 'residual_eigens_lack_beta'\n",
    "df2['eigen_class'] = 'residual_eigens_complete'\n",
    "\n",
    "df = pd.concat([df1,df2,df2_mom,df2_str,df2_beta,df2_value,df2_vol,df2_size])\n",
    "x_col='date'\n",
    "y_col = 'first_eigens'\n",
    "fig = plt.figure(figsize=(50,4))\n",
    "fig.add_subplot(1,1,1)\n",
    "sns.pointplot(x=x_col,y=y_col,data=df,hue='eigen_class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribution=np.mean(ratio, axis=0)\n",
    "print('The average contribution of %s is %.5f'% ('size', contribution[0]))\n",
    "print('The average contribution of %s is %.5f'% ('mom', contribution[1]))\n",
    "print('The average contribution of %s is %.5f'% ('str', contribution[2]))\n",
    "print('The average contribution of %s is %.5f'% ('value', contribution[3]))\n",
    "print('The average contribution of %s is %.5f'% ('vol', contribution[4]))\n",
    "print('The average contribution of %s is %.5f'% ('beta', contribution[5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "date = pd.period_range(\"2006-01\", freq=\"M\", periods=156)\n",
    "df_size = pd.DataFrame({\"date\":date, \"variance_ratio\" : [i[0] for i in ratio]})\n",
    "df_mom = pd.DataFrame({\"date\":date, \"variance_ratio\" : [i[1] for i in ratio]})\n",
    "df_str = pd.DataFrame({\"date\":date, \"variance_ratio\" : [i[2] for i in ratio]})\n",
    "df_value = pd.DataFrame({\"date\":date, \"variance_ratio\" : [i[3] for i in ratio]})\n",
    "df_vol = pd.DataFrame({\"date\":date, \"variance_ratio\" : [i[4] for i in ratio]})\n",
    "df_beta = pd.DataFrame({\"date\":date, \"variance_ratio\" : [i[5] for i in ratio]})\n",
    "\n",
    "df_size['contribution'] = 'size_variance_ratio_contribution'\n",
    "df_mom['contribution'] = 'mom_variance_ratio_contribution'\n",
    "df_str['contribution'] = 'str_variance_ratio_contribution'\n",
    "df_value['contribution'] = 'value_variance_ratio_contribution'\n",
    "df_vol['contribution'] = 'vol_variance_ratio_contribution'\n",
    "df_beta['contribution'] = 'beta_variance_ratio_contribution'\n",
    "\n",
    "\n",
    "df = pd.concat([df_size, df_mom, df_str, df_value, df_vol, df_beta])\n",
    "x_col='date'\n",
    "y_col = 'variance_ratio'\n",
    "sns.pointplot(x=x_col,y=y_col,data=df,alpha=0.0001,hue='contribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
